{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["ykBk_DEpItgo","fTc8XBGLkdZO","bvcYX6wkkjPr","ZqLEZq0zIvOE"],"mount_file_id":"1ASb6N5tISBl_AW2IsRV0ge10ei0gpZto","authorship_tag":"ABX9TyN7SwCMD9h3sztITMK3fWZ+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Preparation for Visualization"],"metadata":{"id":"foHOTNOdJZGs"}},{"cell_type":"markdown","source":["## Model Loading and Environment Configuration"],"metadata":{"id":"ykBk_DEpItgo"}},{"cell_type":"markdown","source":["### Environment Setup (Drive Mount & Project Clone)"],"metadata":{"id":"fTc8XBGLkdZO"}},{"cell_type":"code","source":["# ============================\n","# 1. Mount Google Drive (optional)\n","# ============================\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# ============================\n","# 2. 기본 작업 디렉토리 설정\n","# ============================\n","import os\n","from pathlib import Path\n","\n","base_dir = Path(\"/content/drive/MyDrive/Colab Notebooks\")\n","os.makedirs(base_dir, exist_ok=True)\n","%cd {base_dir}\n","\n","# ============================\n","# 3. Repository clone or skip\n","# ============================\n","repo_url = \"https://github.com/seo-1004/cv-team5-anomaly-detection.git\"\n","repo_dir = base_dir / \"cv-team5-anomaly-detection\"\n","\n","if not repo_dir.exists():\n","    print(\"Repository not found. Cloning...\")\n","    !git clone {repo_url}\n","else:\n","    print(\"Repository already exists. Skipping clone.\")\n","\n","%cd {repo_dir}\n","\n","# ============================\n","# 4. Model checkpoint 확인 후 setup.sh 실행\n","# ============================\n","model_path = \"checkpoints/autoencoder/best_model_epoch_100.pth\"\n","\n","if not os.path.exists(model_path):\n","    print(\"Model not found. Running setup.sh to download/setup model...\")\n","    !bash setup.sh\n","else:\n","    print(\"Model already exists. Skipping setup.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwZjr4IeimvT","executionInfo":{"status":"ok","timestamp":1765603262614,"user_tz":-540,"elapsed":19680,"user":{"displayName":"김서현","userId":"08818282308943516715"}},"outputId":"c1d271bf-72b0-4db1-9020-8b7e1e7aea94"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks\n","Repository already exists. Skipping clone.\n","/content/drive/MyDrive/Colab Notebooks/cv-team5-anomaly-detection\n","Model already exists. Skipping setup.\n"]}]},{"cell_type":"markdown","source":["### Environment & Model Initialization"],"metadata":{"id":"bvcYX6wkkjPr"}},{"cell_type":"code","source":["# Environment & Model Initialization\n","import os\n","import sys\n","import cv2\n","import glob\n","import torch\n","import numpy as np\n","import gradio as gr\n","from functools import partial\n","import matplotlib.pyplot as plt\n","from src.autoencoder import load_model\n","from src.utils.image_io import denorm_to_uint8\n","from src.dataprep.transforms import NormalMapToTensor\n","\n","print('-' * 126)\n","print(f\"Python Version: {sys.version}\")\n","print(f\"PyTorch Version: {torch.__version__}\")\n","\n","# Select GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device:\", device)\n","\n","print('-' * 126)\n","model_path = 'checkpoints/autoencoder/best_model_epoch_100.pth'\n","model, device = load_model(model_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NLEpIjJFMiXo","executionInfo":{"status":"ok","timestamp":1765603322779,"user_tz":-540,"elapsed":13067,"user":{"displayName":"김서현","userId":"08818282308943516715"}},"outputId":"b0d74cc1-4ca9-4e4c-bc79-fb9e92cf1c52"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------------------------------------------------------------\n","Python Version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n","PyTorch Version: 2.9.0+cpu\n","Device: cpu\n","------------------------------------------------------------------------------------------------------------------------------\n","[load_model] 모델 로드 완료: checkpoints/autoencoder/best_model_epoch_100.pth\n","[load_model] device: cpu\n"]}]},{"cell_type":"markdown","source":["### Function Definitions"],"metadata":{"id":"ZqLEZq0zIvOE"}},{"cell_type":"code","source":["BASE_DIR = Path(\"/content/drive/MyDrive/Colab Notebooks/cv-team5-anomaly-detection\")\n","%cd {BASE_DIR}\n","\n","# The input size used by the Dataset\n","TARGET_SIZE = (256, 256)\n","\n","GLOBAL_VMIN = 0.0\n","GLOBAL_VMAX = 0.10\n","\n","# Transform instance identical to the one used in the Dataset (resize / interpolation)\n","_normal_transform = NormalMapToTensor(size=TARGET_SIZE)\n","\n","\n","# ---------------------------------------------------------\n","# 1. Preprocessing identical to the Dataset pipeline\n","# ---------------------------------------------------------\n","def preprocess_np_for_model(image_np):\n","    \"\"\"\n","    image_np: (H, W, 3), uint8 in [0, 255]  (image received from Gradio)\n","\n","    Dataset pipeline:\n","        Load .npy → [-1, 1], (H, W, 3) → NormalMapToTensor → (3, H, W), [-1, 1]\n","\n","    Here, since the input is PNG:\n","        [0,255] → [0,1] → [-1,1],\n","    followed by passing through the same NormalMapToTensor transform.\n","    \"\"\"\n","    # [0,255] → [0,1] → [-1,1]\n","    img = image_np.astype(np.float32) / 255.0\n","    img = img * 2.0 - 1.0  # Same scale as the normal_np used in the Dataset\n","\n","    # Apply the same transform as in the Dataset (includes resizing)\n","    normal_tensor = _normal_transform(img)  # (3,H,W), [-1,1]\n","\n","    return normal_tensor  # torch.Tensor\n","\n","\n","# ---------------------------------------------------------\n","# 2. Error-map computation identical to evaluator.py\n","# ---------------------------------------------------------\n","def forward_and_error(model, input_tensor, device):\n","    \"\"\"\n","    input_tensor: (3,H,W), [-1,1]\n","    return:\n","      recon_np : (H,W,3) float [-1,1]\n","      heatmap  : (H,W)   float  (pixel-wise mean absolute error)\n","    \"\"\"\n","    model.eval()\n","\n","    with torch.no_grad():\n","        if input_tensor.dim() == 3:\n","            input_tensor = input_tensor.unsqueeze(0).to(device)  # (1,3,H,W)\n","        else:\n","            input_tensor = input_tensor.to(device)\n","\n","        recon_tensor = model(input_tensor)\n","\n","        # Convert tensors back to numpy (same as evaluator.py)\n","        input_np = (\n","            input_tensor[0]\n","            .detach()\n","            .cpu()\n","            .permute(1, 2, 0)\n","            .numpy()\n","        )  # (H,W,3), [-1,1]\n","\n","        recon_np = (\n","            recon_tensor[0]\n","            .detach()\n","            .cpu()\n","            .permute(1, 2, 0)\n","            .numpy()\n","        )  # (H,W,3), [-1,1]\n","\n","        # Error map computation (identical to evaluator.py)\n","        error_map_rgb = np.abs(input_np - recon_np)  # (H,W,3)\n","        heatmap = error_map_rgb.mean(axis=2)         # (H,W)\n","\n","    return recon_np, heatmap\n","\n","\n","# ---------------------------------------------------------\n","# 3. Wrapper for visualization\n","# ---------------------------------------------------------\n","def infer(model, input_tensor, device):\n","    \"\"\"\n","    input_tensor: (3, H, W), [-1,1]\n","    return:\n","        - recon_vis: (H,W,3), uint8 [0,255]  (for visualization)\n","        - heat_vis : (H,W,3), uint8 [0,255]  (colormap visualization)\n","        - heatmap  : (H,W), float (raw error values)\n","    \"\"\"\n","    # 1) Forward pass + error-map computation (same as evaluate_model)\n","    recon_np, heatmap = forward_and_error(model, input_tensor, device)\n","\n","    # 2) Convert reconstructed output into uint8 for visualization\n","    recon_vis = denorm_to_uint8(recon_np)  # (H,W,3) uint8\n","\n","    # 3) Convert heatmap into a visual colormap (similar to evaluator’s cv2.normalize routine)\n","    h_min, h_max = GLOBAL_VMIN, GLOBAL_VMAX\n","    if h_max > h_min:\n","        heat_norm = (heatmap - h_min) / (h_max - h_min)\n","    else:\n","        heat_norm = np.zeros_like(heatmap)\n","\n","    heat_uint8 = (heat_norm * 255).astype(np.uint8)\n","    heat_color = cv2.applyColorMap(heat_uint8, cv2.COLORMAP_JET)\n","    heat_vis = cv2.cvtColor(heat_color, cv2.COLOR_BGR2RGB)\n","\n","    # Upsample for Gradio UI display (does not affect numerical values)\n","    recon_vis = cv2.resize(recon_vis, (512, 512), interpolation=cv2.INTER_LINEAR)\n","    heat_vis = cv2.resize(heat_vis, (512, 512), interpolation=cv2.INTER_NEAREST)\n","\n","    return recon_vis, heat_vis, heatmap\n","\n","\n","# ---------------------------------------------------------\n","# 4. Function called by Gradio\n","# ---------------------------------------------------------\n","def infer_gradio(model, device, image_np):\n","    \"\"\"\n","    Gradio wrapper.\n","      - image_np: (H,W,3) uint8  [0,255]\n","      - return: (recon_vis, matplotlib Figure)\n","    \"\"\"\n","    # 1) Preprocess input identically to the Dataset pipeline\n","    input_tensor = preprocess_np_for_model(image_np)  # (3,H,W), [-1,1]\n","\n","    # 2) Forward pass + error-map computation\n","    recon_vis, _, heatmap = infer(model, input_tensor, device)\n","\n","    # 3) Create matplotlib figure\n","    fig, ax = plt.subplots()\n","    im = ax.imshow(\n","        heatmap,\n","        cmap=\"jet\",\n","        vmin=GLOBAL_VMIN,\n","        vmax=GLOBAL_VMAX,\n","    )\n","    plt.colorbar(im, ax=ax)\n","    ax.set_title(\"Error Map\")\n","    ax.axis(\"off\")\n","\n","    return recon_vis, fig\n"],"metadata":{"id":"5TSVLkAbIOTL","executionInfo":{"status":"ok","timestamp":1765603327681,"user_tz":-540,"elapsed":20,"user":{"displayName":"김서현","userId":"08818282308943516715"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f13a388a-5015-4e4c-93c5-22292287e11c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/cv-team5-anomaly-detection\n"]}]},{"cell_type":"markdown","source":["# UI Construction and Execution"],"metadata":{"id":"7CiMwjfmJDFs"}},{"cell_type":"code","source":["\n","with gr.Blocks() as demo:\n","    gr.Markdown(\"## AutoEncoder-based Anomaly Detection Demo\")\n","\n","    with gr.Row():\n","        with gr.Column(scale=2):\n","            input_img = gr.Image(type=\"numpy\", label=\"Input\", width=512, height=512)\n","        with gr.Column(scale=2):\n","            gr.HTML(\"<div style='height:5px'></div>\")\n","            recon_img = gr.Image(label=\"Reconstructed\", width=512, height=412)\n","        with gr.Column(scale=2):\n","            gr.HTML(\"<div style='height:30px'></div>\")\n","            error_plot = gr.Plot(label=\"Error Map\")\n","\n","    with gr.Row():\n","        clear_btn = gr.Button(\"Clear\", scale=1)\n","        submit_btn = gr.Button(\"Submit\", scale=1, variant=\"primary\")\n","\n","    infer_fn = partial(infer_gradio, model, device)\n","\n","    submit_btn.click(\n","        fn=infer_fn,\n","        inputs=input_img,\n","        outputs=[recon_img, error_plot],\n","    )\n","\n","    clear_btn.click(\n","        fn=lambda: (None, None, None),\n","        inputs=None,\n","        outputs=[input_img, recon_img, error_plot],\n","    )\n","\n","demo.launch(\n","    share=True,\n","    debug=False,\n","    quiet=True,\n","    inline=False,\n","    inbrowser=True,\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X6PFCdtJzKh3","executionInfo":{"status":"ok","timestamp":1765603335500,"user_tz":-540,"elapsed":2400,"user":{"displayName":"김서현","userId":"08818282308943516715"}},"outputId":"f0f50d8c-0eaa-4aee-b712-62884982ffd2"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["* Running on public URL: https://02a95f5048087be74e.gradio.live\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":5}]}]}